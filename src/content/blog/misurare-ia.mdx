---
title: "Stai misurando l'AI nel modo sbagliato"
summary: "Il 60% dei manager ammette di aver bisogno di KPI migliori per l'AI. Solo il 34% sta facendo qualcosa al riguardo. Nel frattempo, i dati che davvero contano esistono già — ma nessuno li sta guardando."
publishedAt: "2025-12-20"
locale: it
author:
  name: "Irene Burresi"
  avatar: "/images/avatar.png"
  role: "Lead AI Professional"
pillar: "business"
subsection: "framework"
tags: ["KPI", "Metrics", "AI Measurement", "Enterprise AI", "ROI"]
featured: false
draft: false
secondaryPillars: ["methodology", "research"]
---

## Il paradosso della misurazione

*Il 60% dei manager ammette di aver bisogno di KPI migliori per l'AI. Solo il 34% sta facendo qualcosa al riguardo. Nel frattempo, i dati che davvero contano esistono già — ma nessuno li sta guardando.*

C'è un paradosso nei report sull'adozione dell'AI nel 2025. Da un lato, le aziende dichiarano di misurare tutto: deployment completati, ore risparmiate, ticket gestiti, costi ridotti. Dall'altro, il [42% sta abbandonando la maggior parte dei propri progetti AI](https://www.spglobal.com/market-intelligence/en/news-insights/research/2025/10/generative-ai-shows-rapid-growth-but-yields-mixed-results) — più del doppio rispetto all'anno precedente. Il **95% dei pilot**, secondo [MIT NANDA](https://projectnanda.org/), non genera alcun impatto misurabile sul conto economico.

Se misuriamo così tanto, perché falliamo così spesso?

La risposta è che stiamo misurando le cose sbagliate. Le metriche tipiche dell'AI enterprise — tempo risparmiato per task, volume di interazioni automatizzate, costo per query — catturano l'attività, non l'impatto. Dicono se il sistema funziona tecnicamente, non se sta creando o distruggendo valore.

Un paper pubblicato ad agosto 2025 dal Digital Economy Lab di Stanford offre un modello radicalmente diverso di cosa significhi misurare davvero l'AI. E le implicazioni per chi gestisce investimenti tecnologici sono significative.

---

## Il problema delle metriche di vanità

La maggior parte delle dashboard AI aziendali traccia varianti delle stesse metriche: quante richieste processate, quanto tempo risparmiato per interazione, quale percentuale di task automatizzati. Sono numeri che crescono facilmente e si presentano bene nelle slide. Ma hanno un difetto fondamentale: non dicono nulla sull'impatto reale sul business.

Un chatbot che gestisce 10.000 ticket al mese sembra un successo. Ma se quei ticket richiedono comunque escalation umana nel 40% dei casi, se la customer satisfaction è calata, se i clienti più profittevoli stanno migrando ai competitor — il numero di ticket gestiti non cattura nulla di tutto questo.

Il report di S&P Global sul 2025 documenta esattamente questo pattern: aziende che hanno accumulato "deployment" e "pilot completati" solo per scoprire, mesi dopo, che il ROI non si materializzava. I costi erano reali e immediati; i benefici vaghi e sempre rimandati al prossimo trimestre.

Secondo un'analisi MIT Sloan, il **60% dei manager riconosce di aver bisogno di KPI migliori** per l'AI. Ma solo il 34% sta effettivamente usando l'AI per creare nuovi indicatori di performance. La maggioranza continua a usare le stesse metriche che usava per i progetti IT tradizionali — metriche progettate per software deterministico, non per sistemi probabilistici che interagiscono con processi umani complessi.

---

## Cosa significa misurare sul serio

["Canaries in the Coal Mine"](https://digitaleconomy.stanford.edu/publications/canaries-in-the-coal-mine/), il paper di Erik Brynjolfsson, Bharat Chandar e Ruyu Chen pubblicato dallo Stanford Digital Economy Lab, non parla di come le aziende dovrebbero misurare l'AI. Parla di come l'AI sta cambiando il mercato del lavoro. Ma il metodo che usa è esattamente quello che manca alla maggior parte delle valutazioni enterprise.

Gli autori hanno ottenuto accesso ai dati di payroll di ADP — il più grande processore di buste paga negli Stati Uniti, con record mensili di oltre 25 milioni di lavoratori. Non sondaggi, non self-report, non stime: dati amministrativi granulari su chi viene assunto, chi lascia, quanto guadagna, in quale ruolo, in quale azienda.

Hanno poi incrociato questi dati con due metriche di esposizione all'AI: una basata su analisi teorica dei task (quali mansioni sono tecnicamente automatizzabili) e una basata su dati reali di utilizzo (come le persone usano effettivamente Claude, il modello di Anthropic, nel lavoro quotidiano).

Il risultato è una radiografia dell'impatto dell'AI con una granularità senza precedenti. Non "l'AI sta cambiando il lavoro" ma "l'occupazione per sviluppatori software tra 22 e 25 anni è calata del **20% dal picco di fine 2022**, mentre per gli over-35 nelle stesse mansioni è cresciuta dell'8%". Non "alcuni settori sono più esposti" ma "nelle professioni dove l'uso dell'AI è prevalentemente sostitutivo, i giovani perdono occupazione; dove è prevalentemente augmentativo, non c'è declino".

Questo è il tipo di misurazione che dovrebbe informare le decisioni aziendali sull'AI. Non perché le aziende debbano replicare esattamente questo studio, ma perché illustra tre principi che la maggior parte delle metriche enterprise ignora.

---

## Principio 1: Misura gli effetti differenziali, non le medie

Il dato aggregato nasconde più di quanto riveli. Se misuri solo "ore risparmiate dall'AI", non vedi chi sta risparmiando quelle ore e chi sta perdendo il lavoro. Se misuri solo "ticket automatizzati", non vedi quali clienti ricevono servizio peggiore.

Il paper Stanford mostra che l'impatto dell'AI è radicalmente diverso per fasce d'età. I lavoratori tra 22 e 25 anni nelle professioni esposte hanno visto un declino occupazionale del 13% rispetto ai colleghi in ruoli meno esposti. I lavoratori over 30 nelle stesse professioni hanno visto crescita. L'effetto medio è quasi nullo — ma l'effetto reale è una redistribuzione massiva.

Per un CFO, questo significa che le metriche aggregate di produttività possono mascherare costi nascosti. Se l'AI sta aumentando l'output del team senior mentre rende impossibile assumere e formare junior, il gain di breve periodo potrebbe trasformarsi in un problema di pipeline di talenti nel medio. Il paper lo chiama *"paradosso dell'apprendistato"*: le aziende smettono di assumere entry-level perché l'AI fa quei task meglio, ma senza entry-level oggi non avranno senior domani.

**Implicazione pratica**: ogni dashboard AI dovrebbe segmentare l'impatto per ruolo, seniority, team, tipologia di cliente. Un singolo numero di "produttività" è quasi sempre fuorviante.

---

## Principio 2: Distingui automazione da augmentazione

Una delle scoperte più rilevanti del paper riguarda la differenza tra uso sostitutivo e uso complementare dell'AI. Gli autori hanno usato i dati di Anthropic per classificare come le persone usano effettivamente i modelli linguistici: per generare output finali (automazione) o per iterare, apprendere, validare (augmentazione).

Nelle professioni dove l'uso è prevalentemente automativo, l'occupazione giovanile è crollata. Dove l'uso è prevalentemente augmentativo, non si osserva alcun declino — anzi, alcune di queste categorie mostrano crescita sopra la media.

Questo ha implicazioni dirette per come le aziende dovrebbero valutare i propri progetti AI. Non tutti i "deployment" sono uguali. Un sistema che genera automaticamente report finanziari sostituisce lavoro umano in modo diverso da uno che aiuta gli analisti a esplorare scenari. Le metriche dovrebbero catturare questa distinzione.

**Implicazione pratica**: classificare ogni applicazione AI come prevalentemente sostitutiva o complementare. Tracciare separatamente l'impatto su headcount, skill mix, capacità di formazione interna. I sistemi augmentativi potrebbero avere ROI meno immediato ma effetti più sostenibili.

---

## Principio 3: Controlla per gli shock esterni

Uno degli aspetti metodologici più sofisticati del paper Stanford è l'uso di effetti fissi impresa-tempo. In pratica, gli autori confrontano lavoratori all'interno della stessa azienda nello stesso mese, isolando così l'effetto dell'esposizione AI da qualsiasi altro fattore che colpisce l'azienda (tagli di budget, rallentamento settoriale, cambi di strategia).

Il risultato: anche controllando per tutti questi fattori, i giovani nelle mansioni esposte all'AI mostrano un declino relativo del **16%** rispetto ai colleghi in mansioni non esposte nella stessa azienda.

Questo tipo di rigore è raro nelle valutazioni aziendali. Quando un progetto AI viene lanciato e i costi calano, è facile attribuire il merito all'AI. Ma forse i costi sarebbero calati comunque per fattori stagionali. Forse il team stava già ottimizzando prima del lancio. Forse il confronto è con un periodo anomalo.

**Implicazione pratica**: definire baseline e gruppi di controllo prima del lancio. Non confrontare "prima vs dopo" ma "trattati vs non trattati" nello stesso periodo. Usare A/B test dove possibile, o almeno confronti con team/regioni/segmenti che non hanno adottato l'AI.

---

## Verso dashboard economici ad alta frequenza

Nelle sue previsioni per il 2026, Brynjolfsson ha proposto l'idea di *"AI economic dashboards"* — strumenti che tracciano in tempo quasi reale l'impatto dell'AI sull'economia, aggiornati mensilmente invece che con i ritardi tipici delle statistiche ufficiali.

È una proposta ambiziosa a livello macro. Ma la logica sottostante è applicabile a livello aziendale: smettere di aspettare report trimestrali per capire se l'AI sta funzionando. Costruire invece sistemi di monitoraggio continuo che catturano gli effetti man mano che si manifestano.

Questo richiede un cambio di mentalità. La maggior parte dei progetti AI viene valutata come un investimento tradizionale: business case ex-ante, review periodiche, post-mortem finale. Ma l'AI non si comporta come un asset tradizionale. I suoi effetti sono distribuiti, emergenti, spesso inattesi. Un sistema di monitoraggio continuo può catturare derive prima che diventino problemi.

Concretamente, questo significa:

**Dati in tempo reale, non retrospettivi.** Se il sistema di payroll può dirvi oggi quante persone sono state assunte ieri in ogni ruolo, potete tracciare l'effetto dell'AI sull'organico con lag di giorni, non mesi. Lo stesso vale per ticket gestiti, vendite chiuse, errori rilevati.

**Metriche leading, non solo lagging.** Il tasso di utilizzo effettivo (quanti dipendenti usano davvero lo strumento AI ogni giorno) è un indicatore anticipatore. Se cala, ci sono problemi prima che si vedano nei numeri di produttività.

**Segmentazione per coorte.** Come il paper Stanford segmenta per età, le dashboard aziendali dovrebbero segmentare per ruolo, tenure, performance pregressa. L'AI potrebbe aiutare i top performer mentre danneggia gli altri — o viceversa.

**Confronti interni.** Team che hanno adottato l'AI vs team che non l'hanno fatto. Periodi con feature attiva vs periodi con feature disattivata. Questi confronti sono più informativi dei trend temporali puri.

---

## Il costo del non misurare

C'è un argomento economico diretto per investire in misurazione migliore. Il 42% delle aziende che ha abbandonato progetti AI nel 2025 ha speso budget, tempo, attenzione manageriale per poi non ottenere nulla. Con metriche migliori, alcuni di quei progetti sarebbero stati fermati prima. Altri sarebbero stati corretti in corsa. Altri ancora non sarebbero mai partiti.

Il report MIT NANDA stima che le aziende stiano spendendo **30-40 miliardi di dollari all'anno** in AI generativa. Se il 95% non genera ROI misurabile, stiamo parlando di decine di miliardi bruciati — non perché la tecnologia non funzioni, ma perché viene applicata male, misurata peggio, e quindi non corretta.

Il paper Brynjolfsson offre un modello di cosa potrebbe essere la misurazione dell'AI. Dati amministrativi invece di sondaggi. Granularità demografica invece di medie aggregate. Controlli rigorosi invece di confronti ingenui. Monitoraggio continuo invece di valutazioni puntuali.

Nessuna azienda ha le risorse di Stanford o l'accesso ai dati di ADP. Ma i principi sono trasferibili: segmentare, distinguere automazione da augmentazione, controllare per fattori confondenti, monitorare in tempo reale. Chi adotta questi principi avrà un vantaggio informativo su chi continua a tracciare deployment e ore risparmiate.

---

## La domanda da porsi lunedì mattina

La prossima volta che qualcuno presenta una dashboard AI con metriche in crescita, vale la pena fare alcune domande:

Chi sta beneficiando di questo miglioramento, e chi potrebbe essere danneggiato? Se non possiamo rispondere, non stiamo misurando abbastanza.

L'AI sta sostituendo output o supportando processi? La distinzione ha implicazioni diverse per sostenibilità e rischi.

Come sappiamo che il miglioramento è dovuto all'AI e non ad altri fattori? Se non abbiamo un gruppo di controllo o un baseline rigoroso, non lo sappiamo.

Cosa succederebbe se smettessimo di assumere junior in questo ruolo per i prossimi tre anni? Se non abbiamo una risposta, non stiamo considerando i costi di lungo periodo.

Le aziende che sanno rispondere a queste domande avranno un vantaggio competitivo nel 2026 — non perché hanno l'AI migliore, ma perché sanno se la loro AI sta funzionando.

---

## Fonti

**Stanford Digital Economy Lab**  
[Canaries in the Coal Mine: Six Facts about the Recent Employment Effects of AI](https://digitaleconomy.stanford.edu/publications/canaries-in-the-coal-mine/)

**MIT Sloan Management Review**  
[The Future of Strategic Measurement](https://sloanreview.mit.edu/projects/strategic-measurement-kpis/)

**MIT Project NANDA**  
[The GenAI Divide 2025](https://projectnanda.org/)

**S&P Global Market Intelligence**  
[Generative AI: Rapid Growth, Mixed Results](https://www.spglobal.com/market-intelligence/en/news-insights/research/2025/10/generative-ai-shows-rapid-growth-but-yields-mixed-results)

**Deloitte AI Institute**  
[State of Generative AI in the Enterprise](https://www2.deloitte.com/us/en/pages/consulting/articles/state-of-generative-ai-in-enterprise.html)